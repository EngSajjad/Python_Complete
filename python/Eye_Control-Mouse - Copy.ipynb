{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "912bfeb4",
   "metadata": {},
   "source": [
    "# show camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428fe2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _ , frame = cam.read()\n",
    "    cv2.imshow('eye controled mouse', frame)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fc6fac",
   "metadata": {},
   "source": [
    "# Detect the face(L_2,4,7,8,9,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe12dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh() \n",
    "while True:\n",
    "    _ , frame = cam.read()\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    print(landmark_points)\n",
    "    cv2.imshow('eye controled mouse', frame)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d5fb5c",
   "metadata": {},
   "source": [
    "# Show pixel nummbers of with & height(L_10,11,12,13,14,-15,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51685ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh() \n",
    "while True:\n",
    "    _ , frame = cam.read()\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for landmark in landmarks:\n",
    "            x = landmark.x\n",
    "            y = landmark.y\n",
    "            print(x,y)\n",
    "    cv2.imshow('eye controled mouse', frame)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d00410",
   "metadata": {},
   "source": [
    "# Frame with & height in Decimal numbers(L_10,+14,+15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef785f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh() \n",
    "while True:\n",
    "    _ , frame = cam.read()\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for landmark in landmarks:\n",
    "            x = landmark.x * frame_w\n",
    "            y = landmark.y * frame_h\n",
    "            print(x,y)\n",
    "    cv2.imshow('eye controled mouse', frame)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ae9903",
   "metadata": {},
   "source": [
    "# Frame with & height in integer numbers(L_ +14,+15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7033a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh() \n",
    "while True:\n",
    "    _ , frame = cam.read()\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for landmark in landmarks:\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            print(x,y)\n",
    "    cv2.imshow('eye controled mouse', frame)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b3e68",
   "metadata": {},
   "source": [
    "# Draw circle on frame for center is(x,y) & radius(3) & color for green(0, 255, 0) (L_16) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d040e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh() \n",
    "while True:\n",
    "    _ , frame = cam.read()\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for landmark in landmarks:\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            print(x,y)\n",
    "    cv2.imshow('eye controled mouse', frame)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522a2b63",
   "metadata": {},
   "source": [
    "# For eye Detecting Refining landmarks index in range  of total 478 landmarks.(474:478) (L_+13)\n",
    "* one eye Detect Because By Default image is Fliped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d76478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks = True) \n",
    "while True:\n",
    "    _ , frame = cam.read()\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for landmark in landmarks[474:478]:\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            print(x,y)\n",
    "    cv2.imshow('eye controled mouse', frame)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e8d043",
   "metadata": {},
   "source": [
    "# for fliping verticaly.(L_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a910db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks = True) \n",
    "while True:\n",
    "    _ , frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for landmark in landmarks[474:478]:\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            print(x,y)\n",
    "    cv2.imshow('eye controled mouse', frame)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd520242",
   "metadata": {},
   "source": [
    "# looping landmarks to cursor(L_3,+15,-19,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4254db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui \n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks = True) \n",
    "while True:\n",
    "    _ , frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for id, landmark in enumerate(landmarks[474:478]):\n",
    "            x = int(landmark.x * frame_w) \n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            if id == 1:\n",
    "                pyautogui.moveTo(x,y)\n",
    "    cv2.imshow('eye controled mouse', frame)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d9f6d7",
   "metadata": {},
   "source": [
    "# scaling the screen(L_6,21,22,+23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74085276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui \n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks = True) \n",
    "screen_w, screen_h = pyautogui.size()\n",
    "while True:\n",
    "    _ , frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for id, landmark in enumerate(landmarks[474:478]):\n",
    "            x = int(landmark.x * frame_w) \n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            if id == 1:\n",
    "                screen_x = screen_w / frame_w * x\n",
    "                screen_y = screen_h / frame_h * y\n",
    "                pyautogui.moveTo(screen_x,screen_y)\n",
    "    cv2.imshow('eye controled mouse', frame)\n",
    "    cv2.waitKey(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6973f3",
   "metadata": {},
   "source": [
    "# Right eye for move the cursor & left eye for clicking Detect Landmarks.(L_24,25,26,27,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afc5120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui \n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks = True) \n",
    "screen_w, screen_h = pyautogui.size()\n",
    "while True:\n",
    "    _ , frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for id, landmark in enumerate(landmarks[474:478]):\n",
    "            x = int(landmark.x * frame_w) \n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            if id == 1:\n",
    "                screen_x = screen_w / frame_w * x\n",
    "                screen_y = screen_h / frame_h * y\n",
    "                pyautogui.moveTo(screen_x,screen_y)\n",
    "        left = [landmarks[145], landmarks[159]]\n",
    "        for landmark in left:\n",
    "            x = int(landmark.x * frame_w) \n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 255))\n",
    "    cv2.imshow('eye controled mouse', frame)\n",
    "    cv2.waitKey(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee64ad91",
   "metadata": {},
   "source": [
    "# Getting 2 numbers of vertical position(L_29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97abf0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui \n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks = True) \n",
    "screen_w, screen_h = pyautogui.size()\n",
    "while True:\n",
    "    _ , frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for id, landmark in enumerate(landmarks[474:478]):\n",
    "            x = int(landmark.x * frame_w) \n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            if id == 1:\n",
    "                screen_x = screen_w / frame_w * x\n",
    "                screen_y = screen_h / frame_h * y\n",
    "                pyautogui.moveTo(screen_x,screen_y)\n",
    "        left = [landmarks[145], landmarks[159]]\n",
    "        for landmark in left:\n",
    "            x = int(landmark.x * frame_w) \n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 255))\n",
    "        print(left[0].y, left[1].y)\n",
    "    cv2.imshow('eye controled mouse', frame)\n",
    "    cv2.waitKey(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c443e19",
   "metadata": {},
   "source": [
    "## for Detecting eye blincking. in Line 29 left 0 index - left 1 index(L_+29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a1cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui \n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks = True) \n",
    "screen_w, screen_h = pyautogui.size()\n",
    "while True:\n",
    "    _ , frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for id, landmark in enumerate(landmarks[474:478]):\n",
    "            x = int(landmark.x * frame_w) \n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            if id == 1:\n",
    "                screen_x = screen_w / frame_w * x\n",
    "                screen_y = screen_h / frame_h * y\n",
    "                pyautogui.moveTo(screen_x,screen_y)\n",
    "        left = [landmarks[145], landmarks[159]]\n",
    "        for landmark in left:\n",
    "            x = int(landmark.x * frame_w) \n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 255))\n",
    "        print(left[0].y- left[1].y)\n",
    "    cv2.imshow('eye controled mouse', frame)\n",
    "    cv2.waitKey(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee225f",
   "metadata": {},
   "source": [
    "# Eye blinking Test(L_-29,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d489992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui \n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks = True) \n",
    "screen_w, screen_h = pyautogui.size()\n",
    "while True:\n",
    "    _ , frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for id, landmark in enumerate(landmarks[474:478]):\n",
    "            x = int(landmark.x * frame_w) \n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            if id == 1:\n",
    "                screen_x = screen_w / frame_w * x\n",
    "                screen_y = screen_h / frame_h * y\n",
    "                pyautogui.moveTo(screen_x,screen_y)\n",
    "        left = [landmarks[145], landmarks[159]]\n",
    "        for landmark in left:\n",
    "            x = int(landmark.x * frame_w) \n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 255))\n",
    "        if (left[0].y- left[1].y) <= 0.017:\n",
    "            print(\"click\")\n",
    "    cv2.imshow('eye controled mouse', frame)\n",
    "    cv2.waitKey(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6146432",
   "metadata": {},
   "source": [
    "# Finaly(_-30,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f598d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui \n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks = True) \n",
    "screen_w, screen_h = pyautogui.size()\n",
    "while True:\n",
    "    _ , frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for id, landmark in enumerate(landmarks[474:478]):\n",
    "            x = int(landmark.x * frame_w) \n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            if id == 1:\n",
    "                screen_x = screen_w / frame_w * x\n",
    "                screen_y = screen_h / frame_h * y\n",
    "                pyautogui.moveTo(screen_x,screen_y)\n",
    "        left = [landmarks[145], landmarks[159]]\n",
    "        for landmark in left:\n",
    "            x = int(landmark.x * frame_w) \n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 255))\n",
    "        if (left[0].y- left[1].y) <= 0.017:\n",
    "            pyautogui.click()\n",
    "            pyautogui.sleep(1)\n",
    "    cv2.imshow('eye controled mouse', frame)\n",
    "    cv2.waitKey(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4719177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
